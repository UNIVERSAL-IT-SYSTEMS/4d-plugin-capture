/* --------------------------------------------------------------------------------
 #
 #	4DPlugin.c
 #	source generated by 4D Plugin Wizard
 #	Project : Capture
 #	author : miyako
 #	2013/03/02
 #
 # --------------------------------------------------------------------------------*/


#include "4DPluginAPI.h"
#include "4DPlugin.h"

void PluginMain(int32_t selector, PA_PluginParameters params)
{
	try
	{
		int32_t pProcNum = selector;
		sLONG_PTR *pResult = (sLONG_PTR *)params->fResult;
		PackagePtr pParams = (PackagePtr)params->fParameters;

		CommandDispatcher(pProcNum, pResult, pParams); 
	}
	catch(...)
	{

	}
}

void CommandDispatcher (int32_t pProcNum, sLONG_PTR *pResult, PackagePtr pParams)
{
	switch(pProcNum)
	{
// --- Device

		case 1 :
			CAPTURE_DEVICE_Get_default(pResult, pParams);
			break;

		case 2 :
			CAPTURE_DEVICE_LIST(pResult, pParams);
			break;

// --- Snap

		case 3 :
			CAPTURE_Snap(pResult, pParams);
			break;

	}
}

#pragma mark -

@interface ImageSnap()

#pragma mark -

- (void)captureOutput:(QTCaptureOutput *)captureOutput 
  didOutputVideoFrame:(CVImageBufferRef)videoFrame 
     withSampleBuffer:(QTSampleBuffer *)sampleBuffer 
       fromConnection:(QTCaptureConnection *)connection;

@end

#pragma mark -

@implementation ImageSnap

#pragma mark -

- (id)init{
	self = [super init];
    mCaptureSession = nil;
    mCaptureDeviceInput = nil;
    mCaptureDecompressedVideoOutput = nil;
	mCurrentImageBuffer = nil;
	return self;
}

- (void)dealloc{
	
	if(mCaptureSession)					[mCaptureSession release];
	if(mCaptureDeviceInput)				[mCaptureDeviceInput release];
	if(mCaptureDecompressedVideoOutput)	[mCaptureDecompressedVideoOutput release];
	
    mCaptureSession = nil;
    mCaptureDeviceInput = nil;
    mCaptureDecompressedVideoOutput = nil;	
	
    if(mCurrentImageBuffer) CVBufferRelease(mCurrentImageBuffer);
    
    [super dealloc];
}

#pragma mark -

+ (NSArray *)videoDevices{
    NSMutableArray *results = [NSMutableArray arrayWithCapacity:3];
    [results addObjectsFromArray:[QTCaptureDevice inputDevicesWithMediaType:QTMediaTypeVideo]];
    [results addObjectsFromArray:[QTCaptureDevice inputDevicesWithMediaType:QTMediaTypeMuxed]];
    return results;
}

+ (QTCaptureDevice *)defaultVideoDevice{
	QTCaptureDevice *device = nil;
	device = [QTCaptureDevice defaultInputDeviceWithMediaType:QTMediaTypeVideo];
	if(!device){
        device = [QTCaptureDevice defaultInputDeviceWithMediaType:QTMediaTypeMuxed];
	}
    return device;
}

+(QTCaptureDevice *)deviceForModel:(NSString *)model{
    QTCaptureDevice *result = nil;
    NSArray *devices = [ImageSnap videoDevices];
	for(QTCaptureDevice *device in devices){
        if ([model isEqualToString:[device modelUniqueID]]){
            result = device;
			break;
        }
    }
	
    return result;
}

+(NSImage *)snapshotFromDevice:(QTCaptureDevice *)device{
	
	NSImage *image = nil;
	
    ImageSnap *snap = [[ImageSnap alloc]init];
	
    if([snap startSession:device]){
		
		image = [snap snapshot];   
		
        [snap stopSession];   
		
    } 
    
    [snap release];
	
	return image;
	
}

#pragma mark -

-(NSImage *)snapshot{
	
    CVImageBufferRef frame = nil; 
	
    while(!frame){             
		
        @synchronized(self){             
            frame = mCurrentImageBuffer;      
            CVBufferRetain(frame);       
        }   
		
        if(!frame){  
            [[NSRunLoop currentRunLoop] runUntilDate:[NSDate dateWithTimeIntervalSinceNow: 0.1]];
        }  
		
    } 
    
    NSCIImageRep *imageRep = [NSCIImageRep imageRepWithCIImage:[CIImage imageWithCVImageBuffer:frame]];
    NSImage *image = [[[NSImage alloc] initWithSize:[imageRep size]] autorelease];
    [image addRepresentation:imageRep];
	
    return image;
}

-(void)stopSession{
	
    while(mCaptureSession != nil){
		
        [mCaptureSession stopRunning];
		
        if([mCaptureSession isRunning]){
            [[NSRunLoop currentRunLoop] runUntilDate:[NSDate dateWithTimeIntervalSinceNow:0.1]];
        }else {
			
            if(mCaptureSession)					[mCaptureSession release];
            if(mCaptureDeviceInput)				[mCaptureDeviceInput release];
            if(mCaptureDecompressedVideoOutput)	[mCaptureDecompressedVideoOutput release];
            
            mCaptureSession = nil;
            mCaptureDeviceInput = nil;
            mCaptureDecompressedVideoOutput = nil;
			
        }
    } 
}

-(BOOL)startSession:(QTCaptureDevice *)device{
	
    if(!device){
		return NO;
	}
    
    NSError *error = nil;
    
    if([device isEqual:[mCaptureDeviceInput device]] &&
	   mCaptureSession != nil &&
	   [mCaptureSession isRunning]){
        return YES;
    } 
	
    else if(mCaptureSession){
        [self stopSession];
    }
    
    mCaptureSession = [[QTCaptureSession alloc]init];
	
	if(![device open:&error]){
        [mCaptureSession release];
        mCaptureSession = nil;
		return NO;
	}
	
	mCaptureDeviceInput = [[QTCaptureDeviceInput alloc]initWithDevice:device];
	
	if (![mCaptureSession addInput:mCaptureDeviceInput error:&error]){
        [mCaptureSession release];
        [mCaptureDeviceInput release];
        mCaptureSession = nil;
        mCaptureDeviceInput = nil;
		return NO;
	}
    
	mCaptureDecompressedVideoOutput = [[QTCaptureDecompressedVideoOutput alloc]init];
	[mCaptureDecompressedVideoOutput setDelegate:self];
	
	if (![mCaptureSession addOutput:mCaptureDecompressedVideoOutput error:&error]){
		
        [mCaptureSession release];
        [mCaptureDeviceInput release];
        [mCaptureDecompressedVideoOutput release];
        mCaptureSession = nil;
        mCaptureDeviceInput = nil;
        mCaptureDecompressedVideoOutput = nil;
		return NO;
	}
	
    @synchronized(self){
        if(mCurrentImageBuffer != nil){
            CVBufferRelease(mCurrentImageBuffer);
            mCurrentImageBuffer = nil;
        }
    }
	
	[mCaptureSession startRunning];
    
    return YES;
}  

#pragma mark -

- (void)captureOutput:(QTCaptureOutput *)captureOutput 
  didOutputVideoFrame:(CVImageBufferRef)videoFrame 
     withSampleBuffer:(QTSampleBuffer *)sampleBuffer 
       fromConnection:(QTCaptureConnection *)connection
{
	
    if (videoFrame == nil){
        return;
    }
    
    CVImageBufferRef imageBufferToRelease;
    CVBufferRetain(videoFrame);
	
    @synchronized(self){
        imageBufferToRelease = mCurrentImageBuffer;
        mCurrentImageBuffer = videoFrame;
    }
    CVBufferRelease(imageBufferToRelease);
}

#pragma mark -

@end

// ------------------------------------ Device ------------------------------------

void CAPTURE_DEVICE_Get_default(sLONG_PTR *pResult, PackagePtr pParams)
{
	C_TEXT returnValue;

	QTCaptureDevice *device = [ImageSnap defaultVideoDevice];
	
	if(device){
		returnValue.setUTF16String([device modelUniqueID]);
	}

	returnValue.setReturn(pResult);
}

void CAPTURE_DEVICE_LIST(sLONG_PTR *pResult, PackagePtr pParams)
{
	ARRAY_TEXT models;
	ARRAY_TEXT descriptions;

	models.setSize(1);
	descriptions.setSize(1);
	
	NSArray *devices = [ImageSnap videoDevices];

	for(QTCaptureDevice *device in devices){
		
		models.appendUTF16String([device modelUniqueID]);
		descriptions.appendUTF16String([device localizedDisplayName]);		
		
	}
	
	models.toParamAtIndex(pParams, 1);
	descriptions.toParamAtIndex(pParams, 2);
}

// ------------------------------------- Snap -------------------------------------

void _Snap(SnapContext *context)
{
	NSApplicationLoad();
	
	if(!context->device)
		context->device = [ImageSnap defaultVideoDevice];
	
	if(context->device)
		context->image = [ImageSnap snapshotFromDevice:context->device];
}

void CAPTURE_Snap(sLONG_PTR *pResult, PackagePtr pParams)
{
	C_TEXT Param1;
	C_PICTURE Param2;
	C_LONGINT returnValue;

	Param1.fromParamAtIndex(pParams, 1);
	
	SnapContext context;
	
	NSString *model = Param1.copyUTF16String();
	context.image = nil;
	context.device = [ImageSnap deviceForModel:model];
	[model release];
		
	PA_RunInMainProcess((PA_RunInMainProcessProcPtr)_Snap, &context);

	if(context.image){
		NSData *data = [context.image TIFFRepresentation];
		Param2.setBytes((const uint8_t *)[data bytes], [data length]);
		returnValue.setIntValue(1);	
	}
	
	Param2.toParamAtIndex(pParams, 2);
	returnValue.setReturn(pResult);
}